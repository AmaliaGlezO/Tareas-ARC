{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fitz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfitz\u001b[39;00m  \u001b[38;5;66;03m# PyMuPDF\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Cargar modelo de lenguaje para NLP\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fitz'"
     ]
    }
   ],
   "source": [
    "# procesamiento.py\n",
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import spacy\n",
    "\n",
    "# Cargar modelo de lenguaje para NLP\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extraer_autores_de_pdf(ruta_pdf):\n",
    "    \"\"\"Extrae los nombres de autores de un PDF académico.\"\"\"\n",
    "    doc = fitz.open(ruta_pdf)\n",
    "    texto = \"\"\n",
    "    \n",
    "    # Extraer texto de las primeras páginas (donde suelen estar los autores)\n",
    "    for pagina in doc[:2]:\n",
    "        texto += pagina.get_text()\n",
    "    \n",
    "    # Buscar patrones comunes de secciones de autores\n",
    "    patrones = [\n",
    "        r\"Authors?:\\s*(.+)\",\n",
    "        r\"By\\s*(.+)\",\n",
    "        r\"^([A-Z][a-z]+ [A-Z][a-z]+(?:, | and )?)+\",\n",
    "    ]\n",
    "    \n",
    "    autores = []\n",
    "    for patron in patrones:\n",
    "        coincidencias = re.search(patron, texto, re.MULTILINE)\n",
    "        if coincidencias:\n",
    "            texto_autores = coincidencias.group(1)\n",
    "            # Procesar con NLP para identificar nombres propios\n",
    "            doc_nlp = nlp(texto_autores)\n",
    "            autores = [ent.text for ent in doc_nlp.ents if ent.label_ == \"PERSON\"]\n",
    "            if autores:\n",
    "                break\n",
    "    \n",
    "    return tuple(sorted(set(autores)))  # Elimina duplicados y ordena\n",
    "\n",
    "def procesar_carpeta(carpeta):\n",
    "    \"\"\"Procesa todos los PDFs en una carpeta y devuelve las tuplas de autores.\"\"\"\n",
    "    colaboraciones = []\n",
    "    for archivo in os.listdir(carpeta):\n",
    "        if archivo.endswith(\".pdf\"):\n",
    "            ruta = os.path.join(carpeta, archivo)\n",
    "            autores = extraer_autores_de_pdf(ruta)\n",
    "            if autores:\n",
    "                colaboraciones.append(autores)\n",
    "                print(f\"Procesado {archivo}: {autores}\")\n",
    "    return colaboraciones\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    articulos_dir = \"articulos\"\n",
    "    colaboraciones = procesar_carpeta(articulos_dir)\n",
    "    print(\"\\nResumen de colaboraciones:\")\n",
    "    for i, auts in enumerate(colaboraciones, 1):\n",
    "        print(f\"Artículo {i}: {auts}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
